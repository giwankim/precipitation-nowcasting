{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"../input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Baseline ‚ö°Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, test=False):\n",
    "        self.paths = paths\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        data = np.load(path)\n",
    "        x = data[:, :, :4]\n",
    "        #         x = x / 255.0\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        if self.test:\n",
    "            return x\n",
    "        else:\n",
    "            y = data[:, :, 4]\n",
    "            #             y = y / 255.0\n",
    "            y = y.astype(np.float32)\n",
    "            y = torch.tensor(y, dtype=torch.float)\n",
    "            y = y.unsqueeze(-1)\n",
    "            y = y.permute(2, 0, 1)\n",
    "\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NowcastingDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, test=False, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.test = test\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = 4\n",
    "\n",
    "    def setup(self, stage=\"train\"):\n",
    "        if stage == \"train\":\n",
    "            paths = list((PATH / \"train\").glob(\"*.npy\"))\n",
    "            train_paths, val_paths = model_selection.train_test_split(\n",
    "                paths, test_size=0.1, shuffle=True\n",
    "            )\n",
    "            self.train_dataset = NowcastingDataset(train_paths)\n",
    "            self.val_dataset = NowcastingDataset(val_paths)\n",
    "        else:\n",
    "            test_paths = list((PATH / \"test\").glob(\"*.npy\"))\n",
    "            self.test_dataset = NowcastingDataset(test_paths, test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(x, y=None, test=False):\n",
    "    cmap = plt.cm.get_cmap(\"RdBu\")\n",
    "    cmap = cmap.reversed()\n",
    "    if test:\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "        for i, ax in enumerate(axes):\n",
    "            img = x[:, :, i]\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(10, 10))\n",
    "        for i, ax in enumerate(axes[:-1]):\n",
    "            img = x[:, :, i]\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "        axes[-1].imshow(y[:, :, 0], cmap=cmap)\n",
    "    #     plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = NowcastingDataModule(batch_size=32)\n",
    "datamodule.setup()\n",
    "for batch in datamodule.train_dataloader():\n",
    "    xs, ys = batch\n",
    "    x, y = xs[0], ys[0]\n",
    "    x = x.permute(1, 2, 0).numpy()\n",
    "    y = y.permute(1, 2, 0).numpy()\n",
    "    visualize(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=[4, 64, 128]):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.conv = nn.Conv2d(128, 512, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        x = self.conv(x)\n",
    "        ftrs.append(x)\n",
    "        return ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=[512, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.tr_convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.ConvTranspose2d(chs[i], chs[i + 1], kernel_size=2, stride=2)\n",
    "                for i in range(len(chs) - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(2 * chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, ftrs):\n",
    "        for i, ftr in enumerate(ftrs):\n",
    "            x = self.tr_convs[i](x)\n",
    "            x = torch.cat([ftr, x], dim=1)\n",
    "            x = self.blocks[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, enc_chs=[4, 64, 128], dec_chs=[512, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = self.encoder(x)\n",
    "        ftrs = ftrs[::-1]\n",
    "        x = self.decoder(ftrs[0], ftrs[1:])\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "\n",
    "    def shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        print(f\"Epoch {self.current_epoch} | MAE: {avg_loss}\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = NowcastingDataModule(batch_size=256)\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=10, precision=16, progress_bar_refresh_rate=50, benchmark=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_finder = trainer.tuner.lr_find(model, datamodule)\n",
    "# fig = lr_finder.plot(suggest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.lr = lr_finder.suggestion()\n",
    "# model.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"baseline_bs256_epoch10.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline.load_from_checkpoint(\"baseline_bs256_epoch10.ckpt\")\n",
    "datamodule = NowcastingDataModule(batch_size=128)\n",
    "datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(datamodule.test_dataloader(), total=len(datamodule.test_dataloader())):\n",
    "        batch = batch.to(\"cuda\")\n",
    "        imgs = model(batch)\n",
    "        imgs = imgs.detach().cpu().numpy()\n",
    "        imgs = np.round(imgs)\n",
    "        imgs = np.clip(imgs, 0, 255)\n",
    "        preds.append(imgs)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "preds = preds.astype(np.uint8)\n",
    "preds = preds.reshape(len(preds), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = datamodule.test_dataset.paths\n",
    "test_filenames = [path.name for path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm[\"file_name\"] = test_filenames\n",
    "for i in tqdm(range(14400)):\n",
    "    subm[str(i)] = preds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv(\"baseline_epoch10.csv\", index=False)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
