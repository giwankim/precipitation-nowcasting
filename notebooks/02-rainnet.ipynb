{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import gc\\nimport functools\\nfrom pathlib import Path\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nimport pytorch_lightning as pl\\nfrom torch.utils.data import SequentialSampler, RandomSampler\\n\\nimport optim\\nfrom data import NowcastingDataset\\nfrom loss import LogCoshLoss\\nfrom utils import visualize, radar2precipitation\";\n",
       "                var nbb_formatted_code = \"import gc\\nimport functools\\nfrom pathlib import Path\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nimport pytorch_lightning as pl\\nfrom torch.utils.data import SequentialSampler, RandomSampler\\n\\nimport optim\\nfrom data import NowcastingDataset\\nfrom loss import LogCoshLoss\\nfrom utils import visualize, radar2precipitation\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import functools\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import SequentialSampler, RandomSampler\n",
    "\n",
    "import optim\n",
    "from data import NowcastingDataset\n",
    "from loss import LogCoshLoss\n",
    "from utils import visualize, radar2precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"args = dict(\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=64,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    gradient_accumulation_steps=1,\\n)\";\n",
       "                var nbb_formatted_code = \"args = dict(\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=64,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    gradient_accumulation_steps=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = dict(\n",
    "    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\n",
    "    train_folds_csv=Path(\"../input/train_folds.csv\"),\n",
    "    train_data_path=Path(\"../input/train-128\"),\n",
    "    test_data_path=Path(\"../input/test-128\"),\n",
    "    num_workers=4,\n",
    "    gpus=1,\n",
    "    lr=1e-4,\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    precision=16,\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler=\"cosine\",\n",
    "    gradient_accumulation_steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• RainNet ‚ö°Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Resize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"def resize_data(path, folder=\\\"train-128\\\"):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / folder / path.name, data)\";\n",
       "                var nbb_formatted_code = \"def resize_data(path, folder=\\\"train-128\\\"):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / folder / path.name, data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resize_data(path, folder=\"train-128\"):\n",
    "    data = np.load(path)\n",
    "    img1 = data[:, :, :3]\n",
    "    img2 = data[:, :, 2:]\n",
    "    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\n",
    "    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\n",
    "    img2 = img2[:, :, 1:]\n",
    "    data = np.concatenate([img1, img2], axis=-1)\n",
    "    np.save(PATH / folder / path.name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"(PATH / \\\"train-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_formatted_code = \"(PATH / \\\"train-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(PATH / \"train-128\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def resize_data(path):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / \\\"train-128\\\" / path.name, data)\\n    \\nfiles = list((PATH / \\\"train\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e: e.map(resize_data, files)\";\n",
       "                var nbb_formatted_code = \"def resize_data(path):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / \\\"train-128\\\" / path.name, data)\\n\\n\\nfiles = list((PATH / \\\"train\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(resize_data, files)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = list((PATH / \"train\").glob(\"*.npy\"))\n",
    "with ThreadPoolExecutor(8) as e:\n",
    "    e.map(resize_data, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"(PATH / \\\"test-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_formatted_code = \"(PATH / \\\"test-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(PATH / \"test-128\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"test_files = list((PATH / \\\"test\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(functools.partial(resize_data, folder=\\\"test-128\\\"), test_files)\";\n",
       "                var nbb_formatted_code = \"test_files = list((PATH / \\\"test\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(functools.partial(resize_data, folder=\\\"test-128\\\"), test_files)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_files = list((PATH / \"test\").glob(\"*.npy\"))\n",
    "with ThreadPoolExecutor(8) as e:\n",
    "    e.map(functools.partial(resize_data, folder=\"test-128\"), test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self, train_df, val_df, batch_size=args[\\\"batch_size\\\"], num_workers=args[\\\"num_workers\\\"]\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\"))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_formatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df,\\n        val_df,\\n        batch_size=args[\\\"batch_size\\\"],\\n        num_workers=args[\\\"num_workers\\\"],\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values\\n            ]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\"))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NowcastingDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, train_df, val_df, batch_size=args[\"batch_size\"], num_workers=args[\"num_workers\"]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=\"train\"):\n",
    "        if stage == \"train\":\n",
    "            train_paths = [\n",
    "                args[\"train_data_path\"] / fn for fn in self.train_df.filename.values\n",
    "            ]\n",
    "            val_paths = [args[\"train_data_path\"] / fn for fn in self.val_df.filename.values]\n",
    "            self.train_dataset = NowcastingDataset(train_paths)\n",
    "            self.val_dataset = NowcastingDataset(val_paths)\n",
    "        else:\n",
    "            test_paths = list(args[\"test_data_path\"].glob(\"*.npy\"))\n",
    "            self.test_dataset = NowcastingDataset(test_paths, test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=RandomSampler(self.train_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.val_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.test_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\\n# datamodule.setup()\\n# for batch in datamodule.train_dataloader():\\n#     xs, ys = batch\\n#     idx = np.random.randint(len(xs))\\n#     x, y = xs[idx], ys[idx]\\n#     x = x.permute(1, 2, 0).numpy()\\n#     y = y.permute(1, 2, 0).numpy()\\n#     visualize(x, y)\\n#     break\";\n",
       "                var nbb_formatted_code = \"# df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\\n# datamodule.setup()\\n# for batch in datamodule.train_dataloader():\\n#     xs, ys = batch\\n#     idx = np.random.randint(len(xs))\\n#     x, y = xs[idx], ys[idx]\\n#     x = x.permute(1, 2, 0).numpy()\\n#     y = y.permute(1, 2, 0).numpy()\\n#     visualize(x, y)\\n#     break\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\n",
    "# datamodule.setup()\n",
    "# for batch in datamodule.train_dataloader():\n",
    "#     xs, ys = batch\n",
    "#     idx = np.random.randint(len(xs))\n",
    "#     x, y = xs[idx], ys[idx]\n",
    "#     x = x.permute(1, 2, 0).numpy()\n",
    "#     y = y.permute(1, 2, 0).numpy()\n",
    "#     visualize(x, y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RainNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class Block(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n        )\\n\\n    def forward(self, x):\\n        return self.net(x)\\n\\n\\nclass Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.dropout = nn.Dropout(p=drop_rate)\\n\\n    def forward(self, x):\\n        ftrs = []\\n        for i, block in enumerate(self.blocks):\\n            x = block(x)\\n            ftrs.append(x)\\n            if i >= 3:\\n                x = self.dropout(x)\\n            if i < 4:\\n                x = self.pool(x)\\n        return ftrs\\n\\n\\nclass Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.chs = chs\\n#         self.ups = nn.ModuleList(\\n#             [nn.Upsample(scale_factor=2, mode=\\\"nearest\\\") for i in range(len(chs) - 1)]\\n#         )\\n        self.ups = nn.ModuleList(\\n            [nn.ConvTranspose2d(chs[i], chs[i+1], kernel_size=2, stride=2) for i in range(len(chs) - 1)]\\n        )\\n        self.convs = nn.ModuleList(\\n            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, ftrs):\\n        for i in range(len(self.chs) - 1):\\n            x = self.ups[i](x)\\n            x = torch.cat([ftrs[i], x], dim=1)\\n            x = self.convs[i](x)\\n        return x\";\n",
       "                var nbb_formatted_code = \"class Block(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n        )\\n\\n    def forward(self, x):\\n        return self.net(x)\\n\\n\\nclass Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.dropout = nn.Dropout(p=drop_rate)\\n\\n    def forward(self, x):\\n        ftrs = []\\n        for i, block in enumerate(self.blocks):\\n            x = block(x)\\n            ftrs.append(x)\\n            if i >= 3:\\n                x = self.dropout(x)\\n            if i < 4:\\n                x = self.pool(x)\\n        return ftrs\\n\\n\\nclass Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.chs = chs\\n        #         self.ups = nn.ModuleList(\\n        #             [nn.Upsample(scale_factor=2, mode=\\\"nearest\\\") for i in range(len(chs) - 1)]\\n        #         )\\n        self.ups = nn.ModuleList(\\n            [\\n                nn.ConvTranspose2d(chs[i], chs[i + 1], kernel_size=2, stride=2)\\n                for i in range(len(chs) - 1)\\n            ]\\n        )\\n        self.convs = nn.ModuleList(\\n            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, ftrs):\\n        for i in range(len(self.chs) - 1):\\n            x = self.ups[i](x)\\n            x = torch.cat([ftrs[i], x], dim=1)\\n            x = self.convs[i](x)\\n        return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            if i >= 3:\n",
    "                x = self.dropout(x)\n",
    "            if i < 4:\n",
    "                x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=[1024, 512, 256, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.chs = chs\n",
    "        #         self.ups = nn.ModuleList(\n",
    "        #             [nn.Upsample(scale_factor=2, mode=\"nearest\") for i in range(len(chs) - 1)]\n",
    "        #         )\n",
    "        self.ups = nn.ModuleList(\n",
    "            [\n",
    "                nn.ConvTranspose2d(chs[i], chs[i + 1], kernel_size=2, stride=2)\n",
    "                for i in range(len(chs) - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.convs = nn.ModuleList(\n",
    "            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, ftrs):\n",
    "        for i in range(len(self.chs) - 1):\n",
    "            x = self.ups[i](x)\n",
    "            x = torch.cat([ftrs[i], x], dim=1)\n",
    "            x = self.convs[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RainNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class RainNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=1e-4,\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n\\n        # Parameters\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n\\n        #         self.criterion = LogCoshLoss()\\n        self.criterion = nn.L1Loss()\\n\\n        # Layers\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.out = nn.Sequential(\\n            nn.Conv2d(64, 2, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(2),\\n            nn.Conv2d(2, 1, kernel_size=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        ftrs = self.encoder(x)\\n        ftrs = ftrs[::-1]\\n        x = self.decoder(ftrs[0], ftrs[1:])\\n        out = self.out(x)\\n        return out\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        tfms = nn.Sequential(\\n            T.CenterCrop(120),\\n        )\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = tfms(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = tfms(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        y = 255.0 * y[:, args[\\\"dams\\\"]]\\n        y = np.round(y).clip(0, 255)\\n        y_hat = 255.0 * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = np.round(y_hat).clip(0, 255)\\n        #         mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y = y * y_true\\n        y_hat = y_hat * y_true\\n#         mae = np.abs(y - y_hat).sum() / y_true.sum()\\n        mae = np.abs(y - y_hat).mean()\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.reshape(-1), y_pred.reshape(-1)\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n            optimizer, T_max=self.num_train_steps\\n        )\\n        return [optimizer], [{\\\"scheduler\\\": scheduler, \\\"interval\\\": \\\"step\\\"}]\";\n",
       "                var nbb_formatted_code = \"class RainNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=1e-4,\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n\\n        # Parameters\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n\\n        #         self.criterion = LogCoshLoss()\\n        self.criterion = nn.L1Loss()\\n\\n        # Layers\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.out = nn.Sequential(\\n            nn.Conv2d(64, 2, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(2),\\n            nn.Conv2d(2, 1, kernel_size=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        ftrs = self.encoder(x)\\n        ftrs = ftrs[::-1]\\n        x = self.decoder(ftrs[0], ftrs[1:])\\n        out = self.out(x)\\n        return out\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        tfms = nn.Sequential(\\n            T.CenterCrop(120),\\n        )\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = tfms(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = tfms(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        y = 255.0 * y[:, args[\\\"dams\\\"]]\\n        y = np.round(y).clip(0, 255)\\n        y_hat = 255.0 * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = np.round(y_hat).clip(0, 255)\\n        #         mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y = y * y_true\\n        y_hat = y_hat * y_true\\n        #         mae = np.abs(y - y_hat).sum() / y_true.sum()\\n        mae = np.abs(y - y_hat).mean()\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.reshape(-1), y_pred.reshape(-1)\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n            optimizer, T_max=self.num_train_steps\\n        )\\n        return [optimizer], [{\\\"scheduler\\\": scheduler, \\\"interval\\\": \\\"step\\\"}]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RainNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=1e-4,\n",
    "        enc_chs=[4, 64, 128, 256, 512, 1024],\n",
    "        dec_chs=[1024, 512, 256, 128, 64],\n",
    "        num_train_steps=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.lr = lr\n",
    "        self.num_train_steps = num_train_steps\n",
    "\n",
    "        #         self.criterion = LogCoshLoss()\n",
    "        self.criterion = nn.L1Loss()\n",
    "\n",
    "        # Layers\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.Conv2d(2, 1, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = self.encoder(x)\n",
    "        ftrs = ftrs[::-1]\n",
    "        x = self.decoder(ftrs[0], ftrs[1:])\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "\n",
    "    def shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "        return {\"loss\": loss, \"y\": y.detach(), \"y_hat\": y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"val_loss\", avg_loss)\n",
    "\n",
    "        tfms = nn.Sequential(\n",
    "            T.CenterCrop(120),\n",
    "        )\n",
    "\n",
    "        y = torch.cat([x[\"y\"] for x in outputs])\n",
    "        y = tfms(y)\n",
    "        y = y.detach().cpu().numpy()\n",
    "        y = y.reshape(-1, 120 * 120)\n",
    "\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs])\n",
    "        y_hat = tfms(y_hat)\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1, 120 * 120)\n",
    "\n",
    "        y = 255.0 * y[:, args[\"dams\"]]\n",
    "        y = np.round(y).clip(0, 255)\n",
    "        y_hat = 255.0 * y_hat[:, args[\"dams\"]]\n",
    "        y_hat = np.round(y_hat).clip(0, 255)\n",
    "        #         mae = metrics.mean_absolute_error(y, y_hat)\n",
    "\n",
    "        y_true = radar2precipitation(y)\n",
    "        y_true = np.where(y_true >= 0.1, 1, 0)\n",
    "        y_pred = radar2precipitation(y_hat)\n",
    "        y_pred = np.where(y_pred >= 0.1, 1, 0)\n",
    "\n",
    "        y = y * y_true\n",
    "        y_hat = y_hat * y_true\n",
    "        #         mae = np.abs(y - y_hat).sum() / y_true.sum()\n",
    "        mae = np.abs(y - y_hat).mean()\n",
    "\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(\n",
    "            y_true.reshape(-1), y_pred.reshape(-1)\n",
    "        ).ravel()\n",
    "        csi = tp / (tp + fn + fp)\n",
    "\n",
    "        comp_metric = mae / (csi + 1e-12)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\"\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.num_train_steps\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | L1Loss     | 0     \n",
      "1 | encoder   | Encoder    | 18 M  \n",
      "2 | decoder   | Decoder    | 15 M  \n",
      "3 | out       | Sequential | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101c9fa38ccc4e998ca991d319623ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 1536, 3, 3], expected input[128, 1024, 16, 16] to have 1536 channels, but got 1024 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-04f8cadf4364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"rainnet_fold{fold}_bs64_epoch50.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0;31m# allow no returns from eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode, max_batches)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, test_mode, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# track batch size for weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_backend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mAMPType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNATIVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m__validation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-db83a33b51cb>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y_hat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-db83a33b51cb>\u001b[0m in \u001b[0;36mshared_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-db83a33b51cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mftrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8ff71f44dcf7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, ftrs)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mftrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8ff71f44dcf7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 1536, 3, 3], expected input[128, 1024, 16, 16] to have 1536 channels, but got 1024 channels instead"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n\\nfor fold in range(5):\\n    train_df = df[df.fold != fold]\\n    val_df = df[df.fold == fold]\\n    \\n    datamodule = NowcastingDataModule(\\n        train_df, val_df, batch_size=args[\\\"batch_size\\\"], num_workers=args[\\\"num_workers\\\"]\\n    )\\n    datamodule.setup()\\n\\n    num_train_steps = (\\n        int(\\n            np.ceil(\\n                len(train_df)\\n                // args[\\\"batch_size\\\"]\\n                / args[\\\"gradient_accumulation_steps\\\"]\\n            )\\n        )\\n        * args[\\\"max_epochs\\\"]\\n    )\\n    \\n    model = RainNet(num_train_steps=num_train_steps)\\n    \\n    trainer = pl.Trainer(\\n        gpus=args[\\\"gpus\\\"],\\n        max_epochs=args[\\\"max_epochs\\\"],\\n        precision=args[\\\"precision\\\"],\\n        progress_bar_refresh_rate=50,\\n        benchmark=True,\\n        auto_lr_find=True,\\n    )\\n\\n    trainer.fit(model, datamodule)\\n    trainer.save_checkpoint(f\\\"rainnet_fold{fold}_bs64_epoch50.ckpt\\\")\\n\\n    del datamodule, model, trainer\\n    gc.collect()\\n    torch.cuda.empty_cache()\\n    break\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n\\nfor fold in range(5):\\n    train_df = df[df.fold != fold]\\n    val_df = df[df.fold == fold]\\n\\n    datamodule = NowcastingDataModule(\\n        train_df, val_df, batch_size=args[\\\"batch_size\\\"], num_workers=args[\\\"num_workers\\\"]\\n    )\\n    datamodule.setup()\\n\\n    num_train_steps = (\\n        int(\\n            np.ceil(\\n                len(train_df)\\n                // args[\\\"batch_size\\\"]\\n                / args[\\\"gradient_accumulation_steps\\\"]\\n            )\\n        )\\n        * args[\\\"max_epochs\\\"]\\n    )\\n\\n    model = RainNet(num_train_steps=num_train_steps)\\n\\n    trainer = pl.Trainer(\\n        gpus=args[\\\"gpus\\\"],\\n        max_epochs=args[\\\"max_epochs\\\"],\\n        precision=args[\\\"precision\\\"],\\n        progress_bar_refresh_rate=50,\\n        benchmark=True,\\n        auto_lr_find=True,\\n    )\\n\\n    trainer.fit(model, datamodule)\\n    trainer.save_checkpoint(f\\\"rainnet_fold{fold}_bs64_epoch50.ckpt\\\")\\n\\n    del datamodule, model, trainer\\n    gc.collect()\\n    torch.cuda.empty_cache()\\n    break\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "\n",
    "for fold in range(5):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "\n",
    "    datamodule = NowcastingDataModule(\n",
    "        train_df, val_df, batch_size=args[\"batch_size\"], num_workers=args[\"num_workers\"]\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    num_train_steps = (\n",
    "        int(\n",
    "            np.ceil(\n",
    "                len(train_df)\n",
    "                // args[\"batch_size\"]\n",
    "                / args[\"gradient_accumulation_steps\"]\n",
    "            )\n",
    "        )\n",
    "        * args[\"max_epochs\"]\n",
    "    )\n",
    "\n",
    "    model = RainNet(num_train_steps=num_train_steps)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=args[\"gpus\"],\n",
    "        max_epochs=args[\"max_epochs\"],\n",
    "        precision=args[\"precision\"],\n",
    "        progress_bar_refresh_rate=50,\n",
    "        benchmark=True,\n",
    "        auto_lr_find=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.save_checkpoint(f\"rainnet_fold{fold}_bs64_epoch50.ckpt\")\n",
    "\n",
    "    del datamodule, model, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainNet(\n",
       "  (criterion): L1Loss()\n",
       "  (encoder): Encoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (ups): ModuleList(\n",
       "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (3): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (net): Sequential(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): ReLU(inplace=True)\n",
       "          (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"model = RainNet.load_from_checkpoint(\\\"rainnet_fold0_bs64_epoch50.ckpt\\\")\\nmodel.to(\\\"cuda\\\")\";\n",
       "                var nbb_formatted_code = \"model = RainNet.load_from_checkpoint(\\\"rainnet_fold0_bs64_epoch50.ckpt\\\")\\nmodel.to(\\\"cuda\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RainNet.load_from_checkpoint(\"rainnet_fold0_bs64_epoch50.ckpt\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"datamodule = NowcastingDataModule(train_df, val_df, batch_size=2 * args[\\\"batch_size\\\"])\\ndatamodule.setup(\\\"test\\\")\";\n",
       "                var nbb_formatted_code = \"datamodule = NowcastingDataModule(train_df, val_df, batch_size=2 * args[\\\"batch_size\\\"])\\ndatamodule.setup(\\\"test\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = NowcastingDataModule(train_df, val_df, batch_size=2 * args[\"batch_size\"])\n",
    "datamodule.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"preds = []\\nmodel.eval()\\nwith torch.no_grad():\\n    for batch in datamodule.test_dataloader():\\n        batch = batch.to(\\\"cuda\\\")\\n        imgs = model(batch)\\n        imgs = imgs.detach().cpu().numpy()\\n        imgs = imgs[:, 0, 4:124, 4:124]\\n        imgs = 255.0 * imgs\\n        imgs = np.round(imgs)\\n        imgs = np.clip(imgs, 0, 255)\\n        preds.append(imgs)\\n\\npreds = np.concatenate(preds)\\npreds = preds.astype(np.uint8)\\npreds = preds.reshape(len(preds), -1)\";\n",
       "                var nbb_formatted_code = \"preds = []\\nmodel.eval()\\nwith torch.no_grad():\\n    for batch in datamodule.test_dataloader():\\n        batch = batch.to(\\\"cuda\\\")\\n        imgs = model(batch)\\n        imgs = imgs.detach().cpu().numpy()\\n        imgs = imgs[:, 0, 4:124, 4:124]\\n        imgs = 255.0 * imgs\\n        imgs = np.round(imgs)\\n        imgs = np.clip(imgs, 0, 255)\\n        preds.append(imgs)\\n\\npreds = np.concatenate(preds)\\npreds = preds.astype(np.uint8)\\npreds = preds.reshape(len(preds), -1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(datamodule.test_dataloader()):\n",
    "        batch = batch.to(\"cuda\")\n",
    "        imgs = model(batch)\n",
    "        imgs = imgs.detach().cpu().numpy()\n",
    "        imgs = imgs[:, 0, 4:124, 4:124]\n",
    "        imgs = 255.0 * imgs\n",
    "        imgs = np.round(imgs)\n",
    "        imgs = np.clip(imgs, 0, 255)\n",
    "        preds.append(imgs)\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "preds = preds.astype(np.uint8)\n",
    "preds = preds.reshape(len(preds), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_formatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_paths = datamodule.test_dataset.paths\n",
    "test_filenames = [path.name for path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aa02094dbe4d8f8ddc835f0c523658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"subm = pd.DataFrame()\\nsubm[\\\"file_name\\\"] = test_filenames\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = preds[:, i]\";\n",
       "                var nbb_formatted_code = \"subm = pd.DataFrame()\\nsubm[\\\"file_name\\\"] = test_filenames\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = preds[:, i]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm[\"file_name\"] = test_filenames\n",
    "for i in tqdm(range(14400)):\n",
    "    subm[str(i)] = preds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14390</th>\n",
       "      <th>14391</th>\n",
       "      <th>14392</th>\n",
       "      <th>14393</th>\n",
       "      <th>14394</th>\n",
       "      <th>14395</th>\n",
       "      <th>14396</th>\n",
       "      <th>14397</th>\n",
       "      <th>14398</th>\n",
       "      <th>14399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00402.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00365.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00122.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_01822.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_01769.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 14401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  0  1  2  3  4  5  6  7  8  ...  14390  14391  14392  14393  \\\n",
       "0  test_00402.npy  0  0  0  0  0  0  0  0  8  ...      0      0      0      0   \n",
       "1  test_00365.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "2  test_00122.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "3  test_01822.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "4  test_01769.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "\n",
       "   14394  14395  14396  14397  14398  14399  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 14401 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"subm.to_csv(\\\"rainnet_fold0_epoch50.csv\\\", index=False)\\nsubm.head()\";\n",
       "                var nbb_formatted_code = \"subm.to_csv(\\\"rainnet_fold0_epoch50.csv\\\", index=False)\\nsubm.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm.to_csv(\"rainnet_fold0_epoch50.csv\", index=False)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
