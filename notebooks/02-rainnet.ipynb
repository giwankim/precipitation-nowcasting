{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import gc\\nimport functools\\nfrom pathlib import Path\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nimport pytorch_lightning as pl\\nfrom torch.utils.data import SequentialSampler, RandomSampler\\n\\nimport transformers\\n\\nimport optim\\nfrom data import NowcastingDataset\\nfrom loss import LogCoshLoss\\nfrom utils import visualize, radar2precipitation, seed_everything\";\n",
       "                var nbb_formatted_code = \"import gc\\nimport functools\\nfrom pathlib import Path\\nfrom concurrent.futures import ThreadPoolExecutor\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nimport pytorch_lightning as pl\\nfrom torch.utils.data import SequentialSampler, RandomSampler\\n\\nimport transformers\\n\\nimport optim\\nfrom data import NowcastingDataset\\nfrom loss import LogCoshLoss\\nfrom utils import visualize, radar2precipitation, seed_everything\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import functools\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import SequentialSampler, RandomSampler\n",
    "\n",
    "import transformers\n",
    "\n",
    "import optim\n",
    "from data import NowcastingDataset\n",
    "from loss import LogCoshLoss\n",
    "from utils import visualize, radar2precipitation, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"args = dict(\\n    seed=42,\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=64,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    accumulate_grad_batches=2,\\n    gradient_clip_val=5.0,\\n    rng=255.0,\\n)\";\n",
       "                var nbb_formatted_code = \"args = dict(\\n    seed=42,\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=64,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    accumulate_grad_batches=2,\\n    gradient_clip_val=5.0,\\n    rng=255.0,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = dict(\n",
    "    seed=42,\n",
    "    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\n",
    "    train_folds_csv=Path(\"../input/train_folds.csv\"),\n",
    "    train_data_path=Path(\"../input/train-128\"),\n",
    "    test_data_path=Path(\"../input/test-128\"),\n",
    "    num_workers=4,\n",
    "    gpus=1,\n",
    "    lr=1e-4,\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    precision=16,\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler=\"cosine\",\n",
    "    accumulate_grad_batches=2,\n",
    "    gradient_clip_val=5.0,\n",
    "    rng=255.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• RainNet ‚ö°Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Resize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"def resize_data(path, folder=\\\"train-128\\\"):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / folder / path.name, data)\";\n",
       "                var nbb_formatted_code = \"def resize_data(path, folder=\\\"train-128\\\"):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / folder / path.name, data)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resize_data(path, folder=\"train-128\"):\n",
    "    data = np.load(path)\n",
    "    img1 = data[:, :, :3]\n",
    "    img2 = data[:, :, 2:]\n",
    "    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\n",
    "    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\n",
    "    img2 = img2[:, :, 1:]\n",
    "    data = np.concatenate([img1, img2], axis=-1)\n",
    "    np.save(PATH / folder / path.name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74f08af73b76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train-128\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"(PATH / \\\"train-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_formatted_code = \"(PATH / \\\"train-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(PATH / \"train-128\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"def resize_data(path):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / \\\"train-128\\\" / path.name, data)\\n    \\nfiles = list((PATH / \\\"train\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e: e.map(resize_data, files)\";\n",
       "                var nbb_formatted_code = \"def resize_data(path):\\n    data = np.load(path)\\n    img1 = data[:, :, :3]\\n    img2 = data[:, :, 2:]\\n    img1 = cv2.copyMakeBorder(img1, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = cv2.copyMakeBorder(img2, 4, 4, 4, 4, cv2.BORDER_REFLECT)\\n    img2 = img2[:, :, 1:]\\n    data = np.concatenate([img1, img2], axis=-1)\\n    np.save(PATH / \\\"train-128\\\" / path.name, data)\\n\\n\\nfiles = list((PATH / \\\"train\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(resize_data, files)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = list((PATH / \"train\").glob(\"*.npy\"))\n",
    "with ThreadPoolExecutor(8) as e:\n",
    "    e.map(resize_data, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"(PATH / \\\"test-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_formatted_code = \"(PATH / \\\"test-128\\\").mkdir(exist_ok=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(PATH / \"test-128\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"test_files = list((PATH / \\\"test\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(functools.partial(resize_data, folder=\\\"test-128\\\"), test_files)\";\n",
       "                var nbb_formatted_code = \"test_files = list((PATH / \\\"test\\\").glob(\\\"*.npy\\\"))\\nwith ThreadPoolExecutor(8) as e:\\n    e.map(functools.partial(resize_data, folder=\\\"test-128\\\"), test_files)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_files = list((PATH / \"test\").glob(\"*.npy\"))\n",
    "with ThreadPoolExecutor(8) as e:\n",
    "    e.map(functools.partial(resize_data, folder=\"test-128\"), test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class NowcastingDataset(torch.utils.data.Dataset):\\n    def __init__(self, paths, test=False):\\n        self.paths = paths\\n        self.test = test\\n\\n    def __len__(self):\\n        return len(self.paths)\\n\\n    def __getitem__(self, idx):\\n        path = self.paths[idx]\\n        data = np.load(path)\\n        x = data[:, :, :4]\\n        x = x / args[\\\"rng\\\"]\\n        x = x.astype(np.float32)\\n        x = torch.tensor(x, dtype=torch.float)\\n        x = x.permute(2, 0, 1)\\n        if self.test:\\n            return x\\n        else:\\n            y = data[:, :, 4]\\n            y = y / args[\\\"rng\\\"]\\n            y = y.astype(np.float32)\\n            y = torch.tensor(y, dtype=torch.float)\\n            y = y.unsqueeze(-1)\\n            y = y.permute(2, 0, 1)\\n\\n            return x, y\";\n",
       "                var nbb_formatted_code = \"class NowcastingDataset(torch.utils.data.Dataset):\\n    def __init__(self, paths, test=False):\\n        self.paths = paths\\n        self.test = test\\n\\n    def __len__(self):\\n        return len(self.paths)\\n\\n    def __getitem__(self, idx):\\n        path = self.paths[idx]\\n        data = np.load(path)\\n        x = data[:, :, :4]\\n        x = x / args[\\\"rng\\\"]\\n        x = x.astype(np.float32)\\n        x = torch.tensor(x, dtype=torch.float)\\n        x = x.permute(2, 0, 1)\\n        if self.test:\\n            return x\\n        else:\\n            y = data[:, :, 4]\\n            y = y / args[\\\"rng\\\"]\\n            y = y.astype(np.float32)\\n            y = torch.tensor(y, dtype=torch.float)\\n            y = y.unsqueeze(-1)\\n            y = y.permute(2, 0, 1)\\n\\n            return x, y\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NowcastingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, test=False):\n",
    "        self.paths = paths\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        data = np.load(path)\n",
    "        x = data[:, :, :4]\n",
    "        x = x / args[\"rng\"]\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        if self.test:\n",
    "            return x\n",
    "        else:\n",
    "            y = data[:, :, 4]\n",
    "            y = y / args[\"rng\"]\n",
    "            y = y.astype(np.float32)\n",
    "            y = torch.tensor(y, dtype=torch.float)\n",
    "            y = y.unsqueeze(-1)\n",
    "            y = y.permute(2, 0, 1)\n",
    "\n",
    "            return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df=None,\\n        val_df=None,\\n        batch_size=args[\\\"batch_size\\\"],\\n        num_workers=args[\\\"num_workers\\\"],\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values\\n            ]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\"))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_formatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df=None,\\n        val_df=None,\\n        batch_size=args[\\\"batch_size\\\"],\\n        num_workers=args[\\\"num_workers\\\"],\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values\\n            ]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\"))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NowcastingDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df=None,\n",
    "        val_df=None,\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        num_workers=args[\"num_workers\"],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=\"train\"):\n",
    "        if stage == \"train\":\n",
    "            train_paths = [\n",
    "                args[\"train_data_path\"] / fn for fn in self.train_df.filename.values\n",
    "            ]\n",
    "            val_paths = [\n",
    "                args[\"train_data_path\"] / fn for fn in self.val_df.filename.values\n",
    "            ]\n",
    "            self.train_dataset = NowcastingDataset(train_paths)\n",
    "            self.val_dataset = NowcastingDataset(val_paths)\n",
    "        else:\n",
    "            test_paths = list(args[\"test_data_path\"].glob(\"*.npy\"))\n",
    "            self.test_dataset = NowcastingDataset(test_paths, test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=RandomSampler(self.train_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.val_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.test_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\\n# datamodule.setup()\\n# for batch in datamodule.train_dataloader():\\n#     xs, ys = batch\\n#     idx = np.random.randint(len(xs))\\n#     x, y = xs[idx], ys[idx]\\n#     x = x.permute(1, 2, 0).numpy()\\n#     y = y.permute(1, 2, 0).numpy()\\n#     visualize(x, y)\\n#     break\";\n",
       "                var nbb_formatted_code = \"# df = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\\n# datamodule.setup()\\n# for batch in datamodule.train_dataloader():\\n#     xs, ys = batch\\n#     idx = np.random.randint(len(xs))\\n#     x, y = xs[idx], ys[idx]\\n#     x = x.permute(1, 2, 0).numpy()\\n#     y = y.permute(1, 2, 0).numpy()\\n#     visualize(x, y)\\n#     break\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "# datamodule = NowcastingDataModule(df, fold=0, batch_size=2)\n",
    "# datamodule.setup()\n",
    "# for batch in datamodule.train_dataloader():\n",
    "#     xs, ys = batch\n",
    "#     idx = np.random.randint(len(xs))\n",
    "#     x, y = xs[idx], ys[idx]\n",
    "#     x = x.permute(1, 2, 0).numpy()\n",
    "#     y = y.permute(1, 2, 0).numpy()\n",
    "#     visualize(x, y)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RainNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class Block(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n        )\\n\\n    def forward(self, x):\\n        return self.net(x)\\n\\n\\nclass Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.dropout = nn.Dropout(p=drop_rate)\\n\\n    def forward(self, x):\\n        ftrs = []\\n        for i, block in enumerate(self.blocks):\\n            x = block(x)\\n            ftrs.append(x)\\n            if i >= 3:\\n                x = self.dropout(x)\\n            if i < 4:\\n                x = self.pool(x)\\n        return ftrs\\n\\n\\nclass Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.chs = chs\\n        self.ups = nn.ModuleList(\\n            [nn.Upsample(scale_factor=2, mode=\\\"nearest\\\") for i in range(len(chs) - 1)]\\n        )\\n        self.convs = nn.ModuleList(\\n            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, ftrs):\\n        for i in range(len(self.chs) - 1):\\n            x = self.ups[i](x)\\n            x = torch.cat([ftrs[i], x], dim=1)\\n            x = self.convs[i](x)\\n        return x\";\n",
       "                var nbb_formatted_code = \"class Block(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(out_ch),\\n        )\\n\\n    def forward(self, x):\\n        return self.net(x)\\n\\n\\nclass Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\\n        self.dropout = nn.Dropout(p=drop_rate)\\n\\n    def forward(self, x):\\n        ftrs = []\\n        for i, block in enumerate(self.blocks):\\n            x = block(x)\\n            ftrs.append(x)\\n            if i >= 3:\\n                x = self.dropout(x)\\n            if i < 4:\\n                x = self.pool(x)\\n        return ftrs\\n\\n\\nclass Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.chs = chs\\n        self.ups = nn.ModuleList(\\n            [nn.Upsample(scale_factor=2, mode=\\\"nearest\\\") for i in range(len(chs) - 1)]\\n        )\\n        self.convs = nn.ModuleList(\\n            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, ftrs):\\n        for i in range(len(self.chs) - 1):\\n            x = self.ups[i](x)\\n            x = torch.cat([ftrs[i], x], dim=1)\\n            x = self.convs[i](x)\\n        return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=[4, 64, 128, 256, 512, 1024], drop_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            if i >= 3:\n",
    "                x = self.dropout(x)\n",
    "            if i < 4:\n",
    "                x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=[1024, 512, 256, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.chs = chs\n",
    "        self.ups = nn.ModuleList(\n",
    "            [nn.Upsample(scale_factor=2, mode=\"nearest\") for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.convs = nn.ModuleList(\n",
    "            [Block(chs[i] + chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, ftrs):\n",
    "        for i in range(len(self.chs) - 1):\n",
    "            x = self.ups[i](x)\n",
    "            x = torch.cat([ftrs[i], x], dim=1)\n",
    "            x = self.convs[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RainNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"class RainNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=4e-4,\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n\\n        # Parameters\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n\\n        #         self.criterion = LogCoshLoss()\\n        self.criterion = nn.L1Loss()\\n\\n        # Layers\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.out = nn.Sequential(\\n            nn.Conv2d(64, 2, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(2),\\n            nn.Conv2d(2, 1, kernel_size=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        ftrs = self.encoder(x)\\n        ftrs = ftrs[::-1]\\n        x = self.decoder(ftrs[0], ftrs[1:])\\n        out = self.out(x)\\n        return out\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        tfms = nn.Sequential(\\n            T.CenterCrop(120),\\n        )\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = tfms(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = tfms(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        rng = args[\\\"rng\\\"]\\n        y = rng * y[:, args[\\\"dams\\\"]]\\n        y = y.clip(0, 255)\\n        y_hat = rng * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = y_hat.clip(0, 255)\\n        #         mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y *= y_true\\n        y_hat *= y_true\\n        mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.reshape(-1), y_pred.reshape(-1)\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n        #         optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n            optimizer, T_max=self.num_train_steps\\n        )\\n        return [optimizer], [{\\\"scheduler\\\": scheduler, \\\"interval\\\": \\\"step\\\"}]\";\n",
       "                var nbb_formatted_code = \"class RainNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=4e-4,\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n\\n        # Parameters\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n\\n        #         self.criterion = LogCoshLoss()\\n        self.criterion = nn.L1Loss()\\n\\n        # Layers\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.out = nn.Sequential(\\n            nn.Conv2d(64, 2, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n            nn.BatchNorm2d(2),\\n            nn.Conv2d(2, 1, kernel_size=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        ftrs = self.encoder(x)\\n        ftrs = ftrs[::-1]\\n        x = self.decoder(ftrs[0], ftrs[1:])\\n        out = self.out(x)\\n        return out\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        tfms = nn.Sequential(\\n            T.CenterCrop(120),\\n        )\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = tfms(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = tfms(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        rng = args[\\\"rng\\\"]\\n        y = rng * y[:, args[\\\"dams\\\"]]\\n        y = y.clip(0, 255)\\n        y_hat = rng * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = y_hat.clip(0, 255)\\n        #         mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y *= y_true\\n        y_hat *= y_true\\n        mae = metrics.mean_absolute_error(y, y_hat)\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.reshape(-1), y_pred.reshape(-1)\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n        #         optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n            optimizer, T_max=self.num_train_steps\\n        )\\n        return [optimizer], [{\\\"scheduler\\\": scheduler, \\\"interval\\\": \\\"step\\\"}]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RainNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=3e-4,\n",
    "        enc_chs=[4, 64, 128, 256, 512, 1024],\n",
    "        dec_chs=[1024, 512, 256, 128, 64],\n",
    "        num_train_steps=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.lr = lr\n",
    "        self.num_train_steps = num_train_steps\n",
    "\n",
    "        #         self.criterion = LogCoshLoss()\n",
    "#         self.criterion = nn.L1Loss()\n",
    "        self.criterion = nn.SmoothL1Loss()\n",
    "\n",
    "        # Layers\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.Conv2d(2, 1, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = self.encoder(x)\n",
    "        ftrs = ftrs[::-1]\n",
    "        x = self.decoder(ftrs[0], ftrs[1:])\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "\n",
    "    def shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "        return {\"loss\": loss, \"y\": y.detach(), \"y_hat\": y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"val_loss\", avg_loss)\n",
    "\n",
    "        tfms = nn.Sequential(\n",
    "            T.CenterCrop(120),\n",
    "        )\n",
    "\n",
    "        y = torch.cat([x[\"y\"] for x in outputs])\n",
    "        y = tfms(y)\n",
    "        y = y.detach().cpu().numpy()\n",
    "        y = y.reshape(-1, 120 * 120)\n",
    "\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs])\n",
    "        y_hat = tfms(y_hat)\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1, 120 * 120)\n",
    "\n",
    "        rng = args[\"rng\"]\n",
    "        y = rng * y[:, args[\"dams\"]]\n",
    "        y = y.clip(0, 255)\n",
    "        y_hat = rng * y_hat[:, args[\"dams\"]]\n",
    "        y_hat = y_hat.clip(0, 255)\n",
    "        #         mae = metrics.mean_absolute_error(y, y_hat)\n",
    "\n",
    "        y_true = radar2precipitation(y)\n",
    "        y_true = np.where(y_true >= 0.1, 1, 0)\n",
    "        y_pred = radar2precipitation(y_hat)\n",
    "        y_pred = np.where(y_pred >= 0.1, 1, 0)\n",
    "\n",
    "        y *= y_true\n",
    "        y_hat *= y_true\n",
    "        mae = metrics.mean_absolute_error(y, y_hat)\n",
    "\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(\n",
    "            y_true.reshape(-1), y_pred.reshape(-1)\n",
    "        ).ravel()\n",
    "        csi = tp / (tp + fn + fp)\n",
    "\n",
    "        comp_metric = mae / (csi + 1e-12)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\"\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        #         optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.num_train_steps\n",
    "        )\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | L1Loss     | 0     \n",
      "1 | encoder   | Encoder    | 18 M  \n",
      "2 | decoder   | Decoder    | 12 M  \n",
      "3 | out       | Sequential | 1 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f51fcc5cca242d39eb647651880f9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | MAE/CSI: 44.72930992361908 | MAE: 7.238560199737549 | CSI: 0.16183035714285715 | Loss: 0.5618522763252258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950af769e0964c6d97efa2d2285e87db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea8ec474d2e4cc78c9308a5465bde52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:36: RuntimeWarning: overflow encountered in power\n",
      "  z = np.power(10.0, dbz / 10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | MAE/CSI: 3.380227101944409 | MAE: 2.691118001937866 | CSI: 0.7961352657004831 | Loss: 0.013766583986580372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46b071e8fa444e685db515f6149ec09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | MAE/CSI: 3.3351390941183854 | MAE: 2.668205976486206 | CSI: 0.8000283949740896 | Loss: 0.012434015050530434\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e164dc28c284b098404eb60a35e8fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | MAE/CSI: 3.254171461657984 | MAE: 2.6064536571502686 | CSI: 0.8009576901086335 | Loss: 0.012150284834206104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9446cbd1103f44e294c890bd5f9aae8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | MAE/CSI: 2.9932598900167617 | MAE: 2.4145052433013916 | CSI: 0.8066473784489451 | Loss: 0.012062947265803814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10580e41a054d638d692a4e2c62bd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | MAE/CSI: 3.2017156048262843 | MAE: 2.5828773975372314 | CSI: 0.8067166845301893 | Loss: 0.012147068046033382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:36: RuntimeWarning: overflow encountered in power\n",
      "  z = np.power(10.0, dbz / 10.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2725bee46ad64f2a9019c4b30323edba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | MAE/CSI: 3.101806781350983 | MAE: 2.5002763271331787 | CSI: 0.8060709461861093 | Loss: 0.012087756767868996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:36: RuntimeWarning: overflow encountered in power\n",
      "  z = np.power(10.0, dbz / 10.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63deb8a7634444886789fcc1aecde22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | MAE/CSI: 3.7159665055459423 | MAE: 2.9285545349121094 | CSI: 0.788100358422939 | Loss: 0.014243747107684612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61685426cf3e4789aee9aed6fda48dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | MAE/CSI: 3.5832275825526168 | MAE: 2.8243930339813232 | CSI: 0.7882259691598213 | Loss: 0.012260997667908669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe79cfb1ce4f492192f5206e04b7caec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | MAE/CSI: 4.340023416819759 | MAE: 3.3040218353271484 | CSI: 0.761291246152745 | Loss: 0.01332629844546318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/utils.py:36: RuntimeWarning: overflow encountered in power\n",
      "  z = np.power(10.0, dbz / 10.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8daa0e90124bdc8cf0dd380e249734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | MAE/CSI: 8.132752788816978 | MAE: 5.300608158111572 | CSI: 0.6517606394469648 | Loss: 0.017829107120633125\n"
     ]
    }
   ],
   "source": [
    "seed_everything(args[\"seed\"])\n",
    "pl.seed_everything(args[\"seed\"])\n",
    "\n",
    "df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "\n",
    "for fold in range(5):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "\n",
    "    datamodule = NowcastingDataModule(\n",
    "        train_df, val_df, batch_size=args[\"batch_size\"], num_workers=args[\"num_workers\"]\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    num_train_steps = (\n",
    "        int(\n",
    "            np.ceil(\n",
    "                len(train_df) // args[\"batch_size\"] / args[\"accumulate_grad_batches\"]\n",
    "            )\n",
    "        )\n",
    "        * args[\"max_epochs\"]\n",
    "    )\n",
    "\n",
    "    model = RainNet(num_train_steps=num_train_steps)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=args[\"gpus\"],\n",
    "        max_epochs=args[\"max_epochs\"],\n",
    "        precision=args[\"precision\"],\n",
    "        progress_bar_refresh_rate=50,\n",
    "#         accumulate_grad_batches=args[\"accumulate_grad_batches\"],\n",
    "        gradient_clip_val=args[\"gradient_clip_val\"],\n",
    "        #         auto_lr_find=True,\n",
    "#         benchmark=True,\n",
    "    )\n",
    "\n",
    "    # learning rate finder\n",
    "    #     lr_finder = trainer.tuner.lr_find(model, datamodule=datamodule)\n",
    "    #     fig = lr_finder.plot(suggest=True)\n",
    "    #     fig.show()\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.save_checkpoint(f\"rainnet_fold{fold}_bs64_epoch50.ckpt\")\n",
    "\n",
    "    del datamodule, model, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"preds = []\\nmodel.eval()\\nwith torch.no_grad():\\n    for batch in datamodule.test_dataloader():\\n        batch = batch.to(\\\"cuda\\\")\\n        imgs = model(batch)\\n        imgs = imgs.detach().cpu().numpy()\\n        imgs = imgs[:, 0, 4:124, 4:124]\\n        imgs = 255.0 * imgs\\n        imgs = np.round(imgs)\\n        imgs = np.clip(imgs, 0, 255)\\n        preds.append(imgs)\\n\\npreds = np.concatenate(preds)\\npreds = preds.astype(np.uint8)\\npreds = preds.reshape(len(preds), -1)\";\n",
       "                var nbb_formatted_code = \"preds = []\\nmodel.eval()\\nwith torch.no_grad():\\n    for batch in datamodule.test_dataloader():\\n        batch = batch.to(\\\"cuda\\\")\\n        imgs = model(batch)\\n        imgs = imgs.detach().cpu().numpy()\\n        imgs = imgs[:, 0, 4:124, 4:124]\\n        imgs = 255.0 * imgs\\n        imgs = np.round(imgs)\\n        imgs = np.clip(imgs, 0, 255)\\n        preds.append(imgs)\\n\\npreds = np.concatenate(preds)\\npreds = preds.astype(np.uint8)\\npreds = preds.reshape(len(preds), -1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = NowcastingDataModule()\n",
    "datamodule.setup(\"test\")\n",
    "\n",
    "final_preds = np.zeros((len(datamodule.test_dataset), 120, 120))\n",
    "\n",
    "for fold in range(5):\n",
    "    model = RainNet.load_from_checkpoint(f\"rainnet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}.ckpt\")\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(datamodule.test_dataloader()):\n",
    "            batch = batch.to(\"cuda\")\n",
    "            imgs = model(batch)\n",
    "            imgs = imgs.detach().cpu().numpy()\n",
    "            imgs = imgs[:, 0, 4:124, 4:124]\n",
    "            imgs = args[\"rng\"] * imgs\n",
    "            imgs = imgs.clip(0, 255)\n",
    "            imgs = imgs.round()\n",
    "            preds.append(imgs)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    preds = preds.astype(np.uint8)\n",
    "    final_preds += preds\n",
    "    \n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    break\n",
    "    \n",
    "final_preds = final_preds.reshape(-1, 14400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_formatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_paths = datamodule.test_dataset.paths\n",
    "test_filenames = [path.name for path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aa02094dbe4d8f8ddc835f0c523658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"subm = pd.DataFrame()\\nsubm[\\\"file_name\\\"] = test_filenames\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = preds[:, i]\";\n",
       "                var nbb_formatted_code = \"subm = pd.DataFrame()\\nsubm[\\\"file_name\\\"] = test_filenames\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = preds[:, i]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm = pd.DataFrame({\"file_name\": test_filenames})\n",
    "for i in tqdm(range(14400)):\n",
    "    subm[str(i)] = final_preds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14390</th>\n",
       "      <th>14391</th>\n",
       "      <th>14392</th>\n",
       "      <th>14393</th>\n",
       "      <th>14394</th>\n",
       "      <th>14395</th>\n",
       "      <th>14396</th>\n",
       "      <th>14397</th>\n",
       "      <th>14398</th>\n",
       "      <th>14399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00402.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00365.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00122.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_01822.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_01769.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 14401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  0  1  2  3  4  5  6  7  8  ...  14390  14391  14392  14393  \\\n",
       "0  test_00402.npy  0  0  0  0  0  0  0  0  8  ...      0      0      0      0   \n",
       "1  test_00365.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "2  test_00122.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "3  test_01822.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "4  test_01769.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "\n",
       "   14394  14395  14396  14397  14398  14399  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 14401 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"subm.to_csv(\\\"rainnet_fold0_epoch50.csv\\\", index=False)\\nsubm.head()\";\n",
       "                var nbb_formatted_code = \"subm.to_csv(\\\"rainnet_fold0_epoch50.csv\\\", index=False)\\nsubm.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm.to_csv(f\"rainnet_epoch{args['max_epochs']}_lr{args['lr']}.csv\", index=False)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
