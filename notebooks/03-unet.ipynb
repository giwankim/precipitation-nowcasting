{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%matplotlib inline\\n%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext autoreload\\n%autoreload 2\\n%matplotlib inline\\n%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"import gc\\nfrom pathlib import Path\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nfrom torch.utils.data import RandomSampler, SequentialSampler\\nimport pytorch_lightning as pl\\n\\nimport transformers\\n\\nimport optim\\nimport loss\\nfrom utils import visualize, radar2precipitation, seed_everything\";\n",
       "                var nbb_formatted_code = \"import gc\\nfrom pathlib import Path\\nfrom tqdm.notebook import tqdm\\n\\nimport cv2\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom sklearn import metrics\\n\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torchvision.transforms as T\\nfrom torch.utils.data import RandomSampler, SequentialSampler\\nimport pytorch_lightning as pl\\n\\nimport transformers\\n\\nimport optim\\nimport loss\\nfrom utils import visualize, radar2precipitation, seed_everything\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import transformers\n",
    "\n",
    "import optim\n",
    "import loss\n",
    "from utils import visualize, radar2precipitation, seed_everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"args = dict(\\n    seed=42,\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    model_dir=Path(\\\"../models\\\"),\\n    rng=255.0,\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=256,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    accumulate_grad_batches=1,\\n    gradient_clip_val=5.0,\\n)\";\n",
       "                var nbb_formatted_code = \"args = dict(\\n    seed=42,\\n    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\\n    train_folds_csv=Path(\\\"../input/train_folds.csv\\\"),\\n    train_data_path=Path(\\\"../input/train-128\\\"),\\n    test_data_path=Path(\\\"../input/test-128\\\"),\\n    model_dir=Path(\\\"../models\\\"),\\n    rng=255.0,\\n    num_workers=4,\\n    gpus=1,\\n    lr=1e-4,\\n    max_epochs=50,\\n    batch_size=256,\\n    precision=16,\\n    optimizer=\\\"adamw\\\",\\n    scheduler=\\\"cosine\\\",\\n    accumulate_grad_batches=1,\\n    gradient_clip_val=5.0,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = dict(\n",
    "    seed=42,\n",
    "    dams=(6071, 6304, 7026, 7629, 7767, 8944, 11107),\n",
    "    train_folds_csv=Path(\"../input/train_folds.csv\"),\n",
    "    train_data_path=Path(\"../input/train-128\"),\n",
    "    test_data_path=Path(\"../input/test-128\"),\n",
    "    model_dir=Path(\"../models\"),\n",
    "    rng=255.0,\n",
    "    num_workers=4,\n",
    "    gpus=1,\n",
    "    lr=1e-4,\n",
    "    max_epochs=50,\n",
    "    batch_size=256,\n",
    "    precision=16,\n",
    "    optimizer=\"adamw\",\n",
    "    scheduler=\"cosine\",\n",
    "    accumulate_grad_batches=1,\n",
    "    gradient_clip_val=5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class BasicBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        assert in_ch == out_ch\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.BatchNorm2d(out_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\\n        )\\n\\n    def forward(self, x):\\n        return x + self.net(x)\";\n",
       "                var nbb_formatted_code = \"class BasicBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        assert in_ch == out_ch\\n        super().__init__()\\n        self.net = nn.Sequential(\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            nn.BatchNorm2d(out_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\\n        )\\n\\n    def forward(self, x):\\n        return x + self.net(x)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        assert in_ch == out_ch\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class DownBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.id_conv = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=2)\\n        self.net = nn.Sequential(\\n            nn.BatchNorm2d(in_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.MaxPool2d(2),\\n            nn.BatchNorm2d(in_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\\n        )\\n\\n    def forward(self, x):\\n        residual = x\\n        residual = self.id_conv(residual)\\n        x = self.net(x)\\n        return residual + x, x\";\n",
       "                var nbb_formatted_code = \"class DownBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch):\\n        super().__init__()\\n        self.id_conv = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=2)\\n        self.net = nn.Sequential(\\n            nn.BatchNorm2d(in_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.MaxPool2d(2),\\n            nn.BatchNorm2d(in_ch),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\\n        )\\n\\n    def forward(self, x):\\n        residual = x\\n        residual = self.id_conv(residual)\\n        x = self.net(x)\\n        return residual + x, x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.id_conv = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=2)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.BatchNorm2d(in_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        residual = self.id_conv(residual)\n",
    "        x = self.net(x)\n",
    "        return residual + x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"class Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024]):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [DownBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.basic = BasicBlock(chs[-1], chs[-1])\\n\\n    def forward(self, x):\\n        feats = []\\n        for block in self.blocks:\\n            x, feat = block(x)\\n            feats.append(feat)\\n        x = self.basic(x)\\n        feats.append(x)\\n        return feats\";\n",
       "                var nbb_formatted_code = \"class Encoder(nn.Module):\\n    def __init__(self, chs=[4, 64, 128, 256, 512, 1024]):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [DownBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n        self.basic = BasicBlock(chs[-1], chs[-1])\\n\\n    def forward(self, x):\\n        feats = []\\n        for block in self.blocks:\\n            x, feat = block(x)\\n            feats.append(feat)\\n        x = self.basic(x)\\n        feats.append(x)\\n        return feats\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=[4, 64, 128, 256, 512, 1024]):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [DownBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.basic = BasicBlock(chs[-1], chs[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        for block in self.blocks:\n",
    "            x, feat = block(x)\n",
    "            feats.append(feat)\n",
    "        x = self.basic(x)\n",
    "        feats.append(x)\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"class UpBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch, bilinear=False):\\n        super().__init__()\\n        self.id_conv = nn.ConvTranspose2d(\\n            in_ch + in_ch, out_ch, kernel_size=2, stride=2\\n        )\\n        layers = []\\n        if bilinear:\\n            layers.append(nn.Upsample(scale_factor=2, mode=\\\"nearest\\\"))\\n        else:\\n            layers.append(\\n                nn.ConvTranspose2d(in_ch + in_ch, out_ch, kernel_size=2, stride=2)\\n            )\\n        layers.extend(\\n            [\\n                nn.BatchNorm2d(out_ch),\\n                nn.LeakyReLU(inplace=True),\\n                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n                nn.BatchNorm2d(out_ch),\\n                nn.LeakyReLU(inplace=True),\\n                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            ]\\n        )\\n        self.block = nn.Sequential(*layers)\\n\\n    def forward(self, x, feat):\\n        x = torch.cat([x, feat], dim=1)\\n        residual = x\\n        residual = self.id_conv(residual)\\n        x = self.block(x)\\n        return x + residual\";\n",
       "                var nbb_formatted_code = \"class UpBlock(nn.Module):\\n    def __init__(self, in_ch, out_ch, bilinear=False):\\n        super().__init__()\\n        self.id_conv = nn.ConvTranspose2d(\\n            in_ch + in_ch, out_ch, kernel_size=2, stride=2\\n        )\\n        layers = []\\n        if bilinear:\\n            layers.append(nn.Upsample(scale_factor=2, mode=\\\"nearest\\\"))\\n        else:\\n            layers.append(\\n                nn.ConvTranspose2d(in_ch + in_ch, out_ch, kernel_size=2, stride=2)\\n            )\\n        layers.extend(\\n            [\\n                nn.BatchNorm2d(out_ch),\\n                nn.LeakyReLU(inplace=True),\\n                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n                nn.BatchNorm2d(out_ch),\\n                nn.LeakyReLU(inplace=True),\\n                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\\n            ]\\n        )\\n        self.block = nn.Sequential(*layers)\\n\\n    def forward(self, x, feat):\\n        x = torch.cat([x, feat], dim=1)\\n        residual = x\\n        residual = self.id_conv(residual)\\n        x = self.block(x)\\n        return x + residual\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=False):\n",
    "        super().__init__()\n",
    "        self.id_conv = nn.ConvTranspose2d(\n",
    "            in_ch + in_ch, out_ch, kernel_size=2, stride=2\n",
    "        )\n",
    "        layers = []\n",
    "        if bilinear:\n",
    "            layers.append(nn.Upsample(scale_factor=2, mode=\"nearest\"))\n",
    "        else:\n",
    "            layers.append(\n",
    "                nn.ConvTranspose2d(in_ch + in_ch, out_ch, kernel_size=2, stride=2)\n",
    "            )\n",
    "        layers.extend(\n",
    "            [\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.LeakyReLU(inplace=True),\n",
    "                nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            ]\n",
    "        )\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, feat):\n",
    "        x = torch.cat([x, feat], dim=1)\n",
    "        residual = x\n",
    "        residual = self.id_conv(residual)\n",
    "        x = self.block(x)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [UpBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, feats):\\n        for block, feat in zip(self.blocks, feats):\\n            x = block(x, feat)\\n        return x\";\n",
       "                var nbb_formatted_code = \"class Decoder(nn.Module):\\n    def __init__(self, chs=[1024, 512, 256, 128, 64]):\\n        super().__init__()\\n        self.blocks = nn.ModuleList(\\n            [UpBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\\n        )\\n\\n    def forward(self, x, feats):\\n        for block, feat in zip(self.blocks, feats):\\n            x = block(x, feat)\\n        return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=[1024, 512, 256, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [UpBlock(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, feats):\n",
    "        for block, feat in zip(self.blocks, feats):\n",
    "            x = block(x, feat)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# x = torch.randn(3, 4, 128, 128)\\n# encoder = Encoder()\\n# feats = encoder(x)\\n# for feat in feats:\\n#     print(feat.shape)\";\n",
       "                var nbb_formatted_code = \"# x = torch.randn(3, 4, 128, 128)\\n# encoder = Encoder()\\n# feats = encoder(x)\\n# for feat in feats:\\n#     print(feat.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x = torch.randn(3, 4, 128, 128)\n",
    "# encoder = Encoder()\n",
    "# feats = encoder(x)\n",
    "# for feat in feats:\n",
    "#     print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# decoder = Decoder()\\n# x = torch.randn(3, 1024, 4, 4)\\n# feats = list(reversed(feats))[1:]\\n# decoder(x, feats).shape\";\n",
       "                var nbb_formatted_code = \"# decoder = Decoder()\\n# x = torch.randn(3, 1024, 4, 4)\\n# feats = list(reversed(feats))[1:]\\n# decoder(x, feats).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decoder = Decoder()\n",
    "# x = torch.randn(3, 1024, 4, 4)\n",
    "# feats = list(reversed(feats))[1:]\n",
    "# decoder(x, feats).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"class UNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=args[\\\"lr\\\"],\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n        #         self.criterion = nn.SmoothL1Loss()\\n        self.criterion = nn.L1Loss()\\n\\n        self.tail = BasicBlock(4, enc_chs[0])\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.head = nn.Sequential(\\n            nn.ConvTranspose2d(dec_chs[-1], 32, kernel_size=2, stride=2, bias=False),\\n            nn.BatchNorm2d(32),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(32, 1, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        x = self.tail(x)\\n        feats = self.encoder(x)\\n        feats = feats[::-1]\\n        x = self.decoder(feats[0], feats[1:])\\n        x = self.head(x)\\n\\n        return x\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        for i, param_group in enumerate(self.optimizer.param_groups):\\n            self.log(f\\\"lr/lr{i}\\\", param_group[\\\"lr\\\"])\\n\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        crop = T.CenterCrop(120)\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = crop(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = crop(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        y = args[\\\"rng\\\"] * y[:, args[\\\"dams\\\"]]\\n        y = y.clip(0, 255)\\n        y_hat = args[\\\"rng\\\"] * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = y_hat.clip(0, 255)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y *= y_true\\n        y_hat *= y_true\\n        mae = metrics.mean_absolute_error(y, y_hat)\\n        self.log(\\\"mae\\\", mae)\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.ravel(), y_pred.ravel()\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n        self.log(\\\"csi\\\", csi)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n        self.log(\\\"comp_metric\\\", comp_metric)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n        \\n        # Optimizer\\n        if args[\\\"optimizer\\\"] == \\\"adam\\\":\\n            self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"adamw\\\":\\n            self.optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"adagrad\\\":\\n            self.optimizer = torch.optim.Adagrad(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"radam\\\":\\n            self.optimizer = optim.RAdam(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"ranger\\\":\\n            optimizer = optim.RAdam(self.parameters(), lr=self.lr)\\n            self.optimizer = optim.Lookahead(optimizer)\\n        \\n        # Scheduler\\n        if args[\\\"scheduler\\\"] == \\\"cosine\\\":\\n            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n                self.optimizer, T_max=self.num_train_steps\\n            )\\n            return [self.optimizer], [{\\\"scheduler\\\": self.scheduler, \\\"interval\\\": \\\"step\\\"}]\\n        elif args[\\\"scheduler\\\"] == \\\"step\\\":\\n            self.scheduler = torch.optim.lr_scheduler.StepLR()\\n        elif args[\\\"scheduler\\\"] == \\\"plateau\\\":\\n            self.scheduler = torch.optim.lr_scheduler.ReduceLR()\\n        else:\\n            self.scheduler = None\\n            return [self.optimizer]\";\n",
       "                var nbb_formatted_code = \"class UNet(pl.LightningModule):\\n    def __init__(\\n        self,\\n        lr=args[\\\"lr\\\"],\\n        enc_chs=[4, 64, 128, 256, 512, 1024],\\n        dec_chs=[1024, 512, 256, 128, 64],\\n        num_train_steps=None,\\n    ):\\n        super().__init__()\\n        self.lr = lr\\n        self.num_train_steps = num_train_steps\\n        #         self.criterion = nn.SmoothL1Loss()\\n        self.criterion = nn.L1Loss()\\n\\n        self.tail = BasicBlock(4, enc_chs[0])\\n        self.encoder = Encoder(enc_chs)\\n        self.decoder = Decoder(dec_chs)\\n        self.head = nn.Sequential(\\n            nn.ConvTranspose2d(dec_chs[-1], 32, kernel_size=2, stride=2, bias=False),\\n            nn.BatchNorm2d(32),\\n            nn.LeakyReLU(inplace=True),\\n            nn.Conv2d(32, 1, kernel_size=3, padding=1),\\n            nn.ReLU(inplace=True),\\n        )\\n\\n    def forward(self, x):\\n        x = self.tail(x)\\n        feats = self.encoder(x)\\n        feats = feats[::-1]\\n        x = self.decoder(feats[0], feats[1:])\\n        x = self.head(x)\\n\\n        return x\\n\\n    def shared_step(self, batch, batch_idx):\\n        x, y = batch\\n        y_hat = self(x)\\n        loss = self.criterion(y_hat, y)\\n\\n        return loss, y, y_hat\\n\\n    def training_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n        self.log(\\\"train_loss\\\", loss)\\n        for i, param_group in enumerate(self.optimizer.param_groups):\\n            self.log(f\\\"lr/lr{i}\\\", param_group[\\\"lr\\\"])\\n\\n        return {\\\"loss\\\": loss}\\n\\n    def validation_step(self, batch, batch_idx):\\n        loss, y, y_hat = self.shared_step(batch, batch_idx)\\n\\n        return {\\\"loss\\\": loss, \\\"y\\\": y.detach(), \\\"y_hat\\\": y_hat.detach()}\\n\\n    def validation_epoch_end(self, outputs):\\n        avg_loss = torch.stack([x[\\\"loss\\\"] for x in outputs]).mean()\\n        self.log(\\\"val_loss\\\", avg_loss)\\n\\n        crop = T.CenterCrop(120)\\n\\n        y = torch.cat([x[\\\"y\\\"] for x in outputs])\\n        y = crop(y)\\n        y = y.detach().cpu().numpy()\\n        y = y.reshape(-1, 120 * 120)\\n\\n        y_hat = torch.cat([x[\\\"y_hat\\\"] for x in outputs])\\n        y_hat = crop(y_hat)\\n        y_hat = y_hat.detach().cpu().numpy()\\n        y_hat = y_hat.reshape(-1, 120 * 120)\\n\\n        y = args[\\\"rng\\\"] * y[:, args[\\\"dams\\\"]]\\n        y = y.clip(0, 255)\\n        y_hat = args[\\\"rng\\\"] * y_hat[:, args[\\\"dams\\\"]]\\n        y_hat = y_hat.clip(0, 255)\\n\\n        y_true = radar2precipitation(y)\\n        y_true = np.where(y_true >= 0.1, 1, 0)\\n        y_pred = radar2precipitation(y_hat)\\n        y_pred = np.where(y_pred >= 0.1, 1, 0)\\n\\n        y *= y_true\\n        y_hat *= y_true\\n        mae = metrics.mean_absolute_error(y, y_hat)\\n        self.log(\\\"mae\\\", mae)\\n\\n        tn, fp, fn, tp = metrics.confusion_matrix(\\n            y_true.ravel(), y_pred.ravel()\\n        ).ravel()\\n        csi = tp / (tp + fn + fp)\\n        self.log(\\\"csi\\\", csi)\\n\\n        comp_metric = mae / (csi + 1e-12)\\n        self.log(\\\"comp_metric\\\", comp_metric)\\n\\n        print(\\n            f\\\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\\\"\\n        )\\n\\n    def configure_optimizers(self):\\n\\n        # Optimizer\\n        if args[\\\"optimizer\\\"] == \\\"adam\\\":\\n            self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"adamw\\\":\\n            self.optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"adagrad\\\":\\n            self.optimizer = torch.optim.Adagrad(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"radam\\\":\\n            self.optimizer = optim.RAdam(self.parameters(), lr=self.lr)\\n        elif args[\\\"optimizer\\\"] == \\\"ranger\\\":\\n            optimizer = optim.RAdam(self.parameters(), lr=self.lr)\\n            self.optimizer = optim.Lookahead(optimizer)\\n\\n        # Scheduler\\n        if args[\\\"scheduler\\\"] == \\\"cosine\\\":\\n            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\\n                self.optimizer, T_max=self.num_train_steps\\n            )\\n            return [self.optimizer], [{\\\"scheduler\\\": self.scheduler, \\\"interval\\\": \\\"step\\\"}]\\n        elif args[\\\"scheduler\\\"] == \\\"step\\\":\\n            self.scheduler = torch.optim.lr_scheduler.StepLR()\\n        elif args[\\\"scheduler\\\"] == \\\"plateau\\\":\\n            self.scheduler = torch.optim.lr_scheduler.ReduceLR()\\n        else:\\n            self.scheduler = None\\n            return [self.optimizer]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class UNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=args[\"lr\"],\n",
    "        enc_chs=[4, 64, 128, 256, 512, 1024],\n",
    "        dec_chs=[1024, 512, 256, 128, 64],\n",
    "        num_train_steps=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.num_train_steps = num_train_steps\n",
    "        #         self.criterion = nn.SmoothL1Loss()\n",
    "        self.criterion = nn.L1Loss()\n",
    "\n",
    "        self.tail = BasicBlock(4, enc_chs[0])\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.ConvTranspose2d(dec_chs[-1], 32, kernel_size=2, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tail(x)\n",
    "        feats = self.encoder(x)\n",
    "        feats = feats[::-1]\n",
    "        x = self.decoder(feats[0], feats[1:])\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        return loss, y, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        for i, param_group in enumerate(self.optimizer.param_groups):\n",
    "            self.log(f\"lr/lr{i}\", param_group[\"lr\"])\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
    "\n",
    "        return {\"loss\": loss, \"y\": y.detach(), \"y_hat\": y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(\"val_loss\", avg_loss)\n",
    "\n",
    "        crop = T.CenterCrop(120)\n",
    "\n",
    "        y = torch.cat([x[\"y\"] for x in outputs])\n",
    "        y = crop(y)\n",
    "        y = y.detach().cpu().numpy()\n",
    "        y = y.reshape(-1, 120 * 120)\n",
    "\n",
    "        y_hat = torch.cat([x[\"y_hat\"] for x in outputs])\n",
    "        y_hat = crop(y_hat)\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        y_hat = y_hat.reshape(-1, 120 * 120)\n",
    "\n",
    "        y = args[\"rng\"] * y[:, args[\"dams\"]]\n",
    "        y = y.clip(0, 255)\n",
    "        y_hat = args[\"rng\"] * y_hat[:, args[\"dams\"]]\n",
    "        y_hat = y_hat.clip(0, 255)\n",
    "\n",
    "        y_true = radar2precipitation(y)\n",
    "        y_true = np.where(y_true >= 0.1, 1, 0)\n",
    "        y_pred = radar2precipitation(y_hat)\n",
    "        y_pred = np.where(y_pred >= 0.1, 1, 0)\n",
    "\n",
    "        y *= y_true\n",
    "        y_hat *= y_true\n",
    "        mae = metrics.mean_absolute_error(y, y_hat)\n",
    "        self.log(\"mae\", mae)\n",
    "\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(\n",
    "            y_true.ravel(), y_pred.ravel()\n",
    "        ).ravel()\n",
    "        csi = tp / (tp + fn + fp)\n",
    "        self.log(\"csi\", csi)\n",
    "\n",
    "        comp_metric = mae / (csi + 1e-12)\n",
    "        self.log(\"comp_metric\", comp_metric)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {self.current_epoch} | MAE/CSI: {comp_metric} | MAE: {mae} | CSI: {csi} | Loss: {avg_loss}\"\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        # Optimizer\n",
    "        if args[\"optimizer\"] == \"adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        elif args[\"optimizer\"] == \"adamw\":\n",
    "            self.optimizer = transformers.AdamW(self.parameters(), lr=self.lr)\n",
    "        elif args[\"optimizer\"] == \"adagrad\":\n",
    "            self.optimizer = torch.optim.Adagrad(self.parameters(), lr=self.lr)\n",
    "        elif args[\"optimizer\"] == \"radam\":\n",
    "            self.optimizer = optim.RAdam(self.parameters(), lr=self.lr)\n",
    "        elif args[\"optimizer\"] == \"ranger\":\n",
    "            optimizer = optim.RAdam(self.parameters(), lr=self.lr)\n",
    "            self.optimizer = optim.Lookahead(optimizer)\n",
    "\n",
    "        # Scheduler\n",
    "        if args[\"scheduler\"] == \"cosine\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                self.optimizer, T_max=self.num_train_steps\n",
    "            )\n",
    "            return [self.optimizer], [{\"scheduler\": self.scheduler, \"interval\": \"step\"}]\n",
    "        elif args[\"scheduler\"] == \"step\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.StepLR()\n",
    "        elif args[\"scheduler\"] == \"plateau\":\n",
    "            self.scheduler = torch.optim.lr_scheduler.ReduceLR()\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "            return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# m = UNet()\\n# x = torch.randn(3, 4, 128, 128)\\n# m(x).shape\";\n",
       "                var nbb_formatted_code = \"# m = UNet()\\n# x = torch.randn(3, 4, 128, 128)\\n# m(x).shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# m = UNet()\n",
    "# x = torch.randn(3, 4, 128, 128)\n",
    "# m(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"class NowcastingDataset(torch.utils.data.Dataset):\\n    def __init__(self, paths, test=False):\\n        self.paths = paths\\n        self.test = test\\n\\n    def __len__(self):\\n        return len(self.paths)\\n\\n    def __getitem__(self, idx):\\n        path = self.paths[idx]\\n        data = np.load(path)\\n\\n        x = data[:, :, :4]\\n        x = x / args[\\\"rng\\\"]\\n        x = x.astype(np.float32)\\n        x = torch.tensor(x, dtype=torch.float)\\n        x = x.permute(2, 0, 1)\\n        if self.test:\\n            return x\\n        else:\\n            y = data[:, :, 4]\\n\\n            precipitation = radar2precipitation(y)\\n\\n            label = np.zeros(y.shape)\\n            label[precipitation >= 0.1] += 1\\n            label[precipitation >= 1.0] += 1\\n            label[precipitation >= 2.5] += 1\\n            label = torch.tensor(label, dtype=torch.long)\\n            label = label.unsqueeze(0)\\n\\n            y = y / args[\\\"rng\\\"]\\n            y = y.astype(np.float32)\\n            y = torch.tensor(y, dtype=torch.float)\\n            y = y.unsqueeze(-1)\\n            y = y.permute(2, 0, 1)\\n\\n            return x, y, label\";\n",
       "                var nbb_formatted_code = \"class NowcastingDataset(torch.utils.data.Dataset):\\n    def __init__(self, paths, test=False):\\n        self.paths = paths\\n        self.test = test\\n\\n    def __len__(self):\\n        return len(self.paths)\\n\\n    def __getitem__(self, idx):\\n        path = self.paths[idx]\\n        data = np.load(path)\\n\\n        x = data[:, :, :4]\\n        x = x / args[\\\"rng\\\"]\\n        x = x.astype(np.float32)\\n        x = torch.tensor(x, dtype=torch.float)\\n        x = x.permute(2, 0, 1)\\n        if self.test:\\n            return x\\n        else:\\n            y = data[:, :, 4]\\n\\n            precipitation = radar2precipitation(y)\\n\\n            label = np.zeros(y.shape)\\n            label[precipitation >= 0.1] += 1\\n            label[precipitation >= 1.0] += 1\\n            label[precipitation >= 2.5] += 1\\n            label = torch.tensor(label, dtype=torch.long)\\n            label = label.unsqueeze(0)\\n\\n            y = y / args[\\\"rng\\\"]\\n            y = y.astype(np.float32)\\n            y = torch.tensor(y, dtype=torch.float)\\n            y = y.unsqueeze(-1)\\n            y = y.permute(2, 0, 1)\\n\\n            return x, y, label\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NowcastingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, test=False):\n",
    "        self.paths = paths\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        data = np.load(path)\n",
    "\n",
    "        x = data[:, :, :4]\n",
    "        x = x / args[\"rng\"]\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        if self.test:\n",
    "            return x\n",
    "        else:\n",
    "            y = data[:, :, 4]\n",
    "\n",
    "            precipitation = radar2precipitation(y)\n",
    "\n",
    "            label = np.zeros(y.shape)\n",
    "            label[precipitation >= 0.1] += 1\n",
    "            label[precipitation >= 1.0] += 1\n",
    "            label[precipitation >= 2.5] += 1\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            label = label.unsqueeze(0)\n",
    "\n",
    "            y = y / args[\"rng\"]\n",
    "            y = y.astype(np.float32)\n",
    "            y = torch.tensor(y, dtype=torch.float)\n",
    "            y = y.unsqueeze(-1)\n",
    "            y = y.permute(2, 0, 1)\n",
    "\n",
    "            return x, y, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8d4c97fc809b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNowcastingDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"fold = 3\\ndf = pd.read_csv(args[\\\"train_folds_csv\\\"])\\ntrain_df = df[df.fold != fold]\\ntrain_paths = [args[\\\"train_data_path\\\"] / fn for fn in train_df.filename.values]\\ndataset = NowcastingDataset(train_paths)\\nidx = np.random.randint(len(dataset))\\nx, y = dataset[idx]\";\n",
       "                var nbb_formatted_code = \"fold = 3\\ndf = pd.read_csv(args[\\\"train_folds_csv\\\"])\\ntrain_df = df[df.fold != fold]\\ntrain_paths = [args[\\\"train_data_path\\\"] / fn for fn in train_df.filename.values]\\ndataset = NowcastingDataset(train_paths)\\nidx = np.random.randint(len(dataset))\\nx, y = dataset[idx]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold = 3\n",
    "df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "train_df = df[df.fold != fold]\n",
    "train_paths = [args[\"train_data_path\"] / fn for fn in train_df.filename.values]\n",
    "dataset = NowcastingDataset(train_paths)\n",
    "idx = np.random.randint(len(dataset))\n",
    "x, y = dataset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df=None,\\n        val_df=None,\\n        batch_size=args[\\\"batch_size\\\"],\\n        num_workers=args[\\\"num_workers\\\"],\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values\\n            ]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(sorted(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\")))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_formatted_code = \"class NowcastingDataModule(pl.LightningDataModule):\\n    def __init__(\\n        self,\\n        train_df=None,\\n        val_df=None,\\n        batch_size=args[\\\"batch_size\\\"],\\n        num_workers=args[\\\"num_workers\\\"],\\n    ):\\n        super().__init__()\\n        self.train_df = train_df\\n        self.val_df = val_df\\n        self.batch_size = batch_size\\n        self.num_workers = num_workers\\n\\n    def setup(self, stage=\\\"train\\\"):\\n        if stage == \\\"train\\\":\\n            train_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.train_df.filename.values\\n            ]\\n            val_paths = [\\n                args[\\\"train_data_path\\\"] / fn for fn in self.val_df.filename.values\\n            ]\\n            self.train_dataset = NowcastingDataset(train_paths)\\n            self.val_dataset = NowcastingDataset(val_paths)\\n        else:\\n            test_paths = list(sorted(args[\\\"test_data_path\\\"].glob(\\\"*.npy\\\")))\\n            self.test_dataset = NowcastingDataset(test_paths, test=True)\\n\\n    def train_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.train_dataset,\\n            batch_size=self.batch_size,\\n            sampler=RandomSampler(self.train_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n            drop_last=True,\\n        )\\n\\n    def val_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.val_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.val_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\\n\\n    def test_dataloader(self):\\n        return torch.utils.data.DataLoader(\\n            self.test_dataset,\\n            batch_size=2 * self.batch_size,\\n            sampler=SequentialSampler(self.test_dataset),\\n            pin_memory=True,\\n            num_workers=self.num_workers,\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NowcastingDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df=None,\n",
    "        val_df=None,\n",
    "        batch_size=args[\"batch_size\"],\n",
    "        num_workers=args[\"num_workers\"],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=\"train\"):\n",
    "        if stage == \"train\":\n",
    "            train_paths = [\n",
    "                args[\"train_data_path\"] / fn for fn in self.train_df.filename.values\n",
    "            ]\n",
    "            val_paths = [\n",
    "                args[\"train_data_path\"] / fn for fn in self.val_df.filename.values\n",
    "            ]\n",
    "            self.train_dataset = NowcastingDataset(train_paths)\n",
    "            self.val_dataset = NowcastingDataset(val_paths)\n",
    "        else:\n",
    "            test_paths = list(sorted(args[\"test_data_path\"].glob(\"*.npy\")))\n",
    "            self.test_dataset = NowcastingDataset(test_paths, test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            sampler=RandomSampler(self.train_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.val_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            sampler=SequentialSampler(self.test_dataset),\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | L1Loss     | 0     \n",
      "1 | tail      | BasicBlock | 300   \n",
      "2 | encoder   | Encoder    | 25 M  \n",
      "3 | decoder   | Decoder    | 17 M  \n",
      "4 | head      | Sequential | 8 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed004db6ca9f4443b88355a974d0aff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-374e52f4655e>\", line 41, in <module>\n",
      "    trainer.fit(model, datamodule)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 440, in fit\n",
      "    results = self.accelerator_backend.train()\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 54, in train\n",
      "    results = self.train_or_test()\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 68, in train_or_test\n",
      "    results = self.trainer.train()\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 462, in train\n",
      "    self.run_sanity_check(self.get_model())\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in run_sanity_check\n",
      "    _, eval_results = self.run_evaluation(test_mode=False, max_batches=self.num_sanity_val_batches)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 570, in run_evaluation\n",
      "    output = self.evaluation_loop.evaluation_step(test_mode, batch, batch_idx, dataloader_idx)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 171, in evaluation_step\n",
      "    output = self.trainer.accelerator_backend.validation_step(args)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 76, in validation_step\n",
      "    output = self.__validation_step(args)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\", line 86, in __validation_step\n",
      "    output = self.trainer.model.validation_step(*args)\n",
      "  File \"<ipython-input-14-79b0b792c233>\", line 51, in validation_step\n",
      "    loss, y, y_hat = self.shared_step(batch, batch_idx)\n",
      "  File \"<ipython-input-14-79b0b792c233>\", line 36, in shared_step\n",
      "    x, y = batch\n",
      "ValueError: too many values to unpack (expected 2)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/isleof/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/inspect.py\", line 745, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-374e52f4655e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     trainer.save_checkpoint(\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test_mode, max_batches)\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, test_mode, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__validation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m__validation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-79b0b792c233>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-79b0b792c233>\u001b[0m in \u001b[0;36mshared_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshared_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ValueError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/envs/torch2/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"seed_everything(args[\\\"seed\\\"])\\npl.seed_everything(args[\\\"seed\\\"])\\n\\ndf = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n\\nfor fold in range(3, 5):\\n    train_df = df[df.fold != fold]\\n    val_df = df[df.fold == fold]\\n\\n    datamodule = NowcastingDataModule(\\n        train_df, val_df, batch_size=args[\\\"batch_size\\\"], num_workers=args[\\\"num_workers\\\"]\\n    )\\n    datamodule.setup()\\n\\n    num_train_steps = (\\n        int(\\n            np.ceil(\\n                len(train_df) // args[\\\"batch_size\\\"] / args[\\\"accumulate_grad_batches\\\"]\\n            )\\n        )\\n        * args[\\\"max_epochs\\\"]\\n    )\\n\\n    model = UNet(num_train_steps=num_train_steps)\\n\\n    trainer = pl.Trainer(\\n        gpus=args[\\\"gpus\\\"],\\n        max_epochs=args[\\\"max_epochs\\\"],\\n        precision=args[\\\"precision\\\"],\\n        progress_bar_refresh_rate=50,\\n        #         accumulate_grad_batches=args[\\\"accumulate_grad_batches\\\"],\\n        #         gradient_clip_val=args[\\\"gradient_clip_val\\\"],\\n        auto_lr_find=True,\\n    )\\n\\n    # learning rate finder\\n    #     lr_finder = trainer.tuner.lr_find(model, datamodule=datamodule)\\n    #     fig = lr_finder.plot(suggest=True)\\n    #     fig.show()\\n\\n    trainer.fit(model, datamodule)\\n    trainer.save_checkpoint(\\n        args[\\\"model_dir\\\"]\\n        / f\\\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\\\"\\n    )\\n\\n    del datamodule, model, trainer\\n    gc.collect()\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_formatted_code = \"seed_everything(args[\\\"seed\\\"])\\npl.seed_everything(args[\\\"seed\\\"])\\n\\ndf = pd.read_csv(args[\\\"train_folds_csv\\\"])\\n\\nfor fold in range(3, 5):\\n    train_df = df[df.fold != fold]\\n    val_df = df[df.fold == fold]\\n\\n    datamodule = NowcastingDataModule(\\n        train_df, val_df, batch_size=args[\\\"batch_size\\\"], num_workers=args[\\\"num_workers\\\"]\\n    )\\n    datamodule.setup()\\n\\n    num_train_steps = (\\n        int(\\n            np.ceil(\\n                len(train_df) // args[\\\"batch_size\\\"] / args[\\\"accumulate_grad_batches\\\"]\\n            )\\n        )\\n        * args[\\\"max_epochs\\\"]\\n    )\\n\\n    model = UNet(num_train_steps=num_train_steps)\\n\\n    trainer = pl.Trainer(\\n        gpus=args[\\\"gpus\\\"],\\n        max_epochs=args[\\\"max_epochs\\\"],\\n        precision=args[\\\"precision\\\"],\\n        progress_bar_refresh_rate=50,\\n        #         accumulate_grad_batches=args[\\\"accumulate_grad_batches\\\"],\\n        #         gradient_clip_val=args[\\\"gradient_clip_val\\\"],\\n        auto_lr_find=True,\\n    )\\n\\n    # learning rate finder\\n    #     lr_finder = trainer.tuner.lr_find(model, datamodule=datamodule)\\n    #     fig = lr_finder.plot(suggest=True)\\n    #     fig.show()\\n\\n    trainer.fit(model, datamodule)\\n    trainer.save_checkpoint(\\n        args[\\\"model_dir\\\"]\\n        / f\\\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\\\"\\n    )\\n\\n    del datamodule, model, trainer\\n    gc.collect()\\n    torch.cuda.empty_cache()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_everything(args[\"seed\"])\n",
    "pl.seed_everything(args[\"seed\"])\n",
    "\n",
    "df = pd.read_csv(args[\"train_folds_csv\"])\n",
    "\n",
    "for fold in range(3, 5):\n",
    "    train_df = df[df.fold != fold]\n",
    "    val_df = df[df.fold == fold]\n",
    "\n",
    "    datamodule = NowcastingDataModule(\n",
    "        train_df, val_df, batch_size=args[\"batch_size\"], num_workers=args[\"num_workers\"]\n",
    "    )\n",
    "    datamodule.setup()\n",
    "\n",
    "    num_train_steps = (\n",
    "        int(\n",
    "            np.ceil(\n",
    "                len(train_df) // args[\"batch_size\"] / args[\"accumulate_grad_batches\"]\n",
    "            )\n",
    "        )\n",
    "        * args[\"max_epochs\"]\n",
    "    )\n",
    "\n",
    "    model = UNet(num_train_steps=num_train_steps)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=args[\"gpus\"],\n",
    "        max_epochs=args[\"max_epochs\"],\n",
    "        precision=args[\"precision\"],\n",
    "        progress_bar_refresh_rate=50,\n",
    "        #         accumulate_grad_batches=args[\"accumulate_grad_batches\"],\n",
    "        #         gradient_clip_val=args[\"gradient_clip_val\"],\n",
    "        auto_lr_find=True,\n",
    "    )\n",
    "\n",
    "    # learning rate finder\n",
    "    #     lr_finder = trainer.tuner.lr_find(model, datamodule=datamodule)\n",
    "    #     fig = lr_finder.plot(suggest=True)\n",
    "    #     fig.show()\n",
    "\n",
    "    trainer.fit(model, datamodule)\n",
    "    trainer.save_checkpoint(\n",
    "        args[\"model_dir\"]\n",
    "        / f\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\"\n",
    "    )\n",
    "\n",
    "    del datamodule, model, trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/unet_fold0_bs256_epoch50_adamw_cosine.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209aa235815347a9b2522aba0e43f37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../models/unet_fold1_bs256_epoch50_adamw_cosine.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10755cf46d21468e8109a77e1f278596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../models/unet_fold2_bs256_epoch50_adamw_cosine.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf62d681150647e5b1397731d1484a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../models/unet_fold3_bs256_epoch50_adamw_cosine.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687733fd26c745d8a01ff94af632ffeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "../models/unet_fold4_bs256_epoch50_adamw_cosine.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350aa5098fd3423aa7487492fcf1ec48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"datamodule = NowcastingDataModule()\\ndatamodule.setup(\\\"test\\\")\\n\\nfinal_preds = np.zeros((len(datamodule.test_dataset), 120, 120))\\n\\nfor fold in range(5):\\n    checkpoint = (\\n        args[\\\"model_dir\\\"]\\n        / f\\\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\\\"\\n    )\\n    print(checkpoint)\\n    model = UNet.load_from_checkpoint(str(checkpoint))\\n    model.cuda()\\n    model.eval()\\n    preds = []\\n    with torch.no_grad():\\n        for batch in tqdm(datamodule.test_dataloader()):\\n            batch = batch.cuda()\\n            imgs = model(batch)\\n            imgs = imgs.detach().cpu().numpy()\\n            imgs = imgs[:, 0, 4:124, 4:124]\\n            imgs = args[\\\"rng\\\"] * imgs\\n            imgs = imgs.clip(0, 255)\\n            imgs = imgs.round()\\n            preds.append(imgs)\\n\\n    preds = np.concatenate(preds)\\n    preds = preds.astype(np.uint8)\\n    final_preds += preds\\n\\n    del model\\n    gc.collect()\\n    torch.cuda.empty_cache()\\n\\nfinal_preds = final_preds.astype(np.uint8)\\nfinal_preds = final_preds.reshape(-1, 14400)\";\n",
       "                var nbb_formatted_code = \"datamodule = NowcastingDataModule()\\ndatamodule.setup(\\\"test\\\")\\n\\nfinal_preds = np.zeros((len(datamodule.test_dataset), 120, 120))\\n\\nfor fold in range(5):\\n    checkpoint = (\\n        args[\\\"model_dir\\\"]\\n        / f\\\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\\\"\\n    )\\n    print(checkpoint)\\n    model = UNet.load_from_checkpoint(str(checkpoint))\\n    model.cuda()\\n    model.eval()\\n    preds = []\\n    with torch.no_grad():\\n        for batch in tqdm(datamodule.test_dataloader()):\\n            batch = batch.cuda()\\n            imgs = model(batch)\\n            imgs = imgs.detach().cpu().numpy()\\n            imgs = imgs[:, 0, 4:124, 4:124]\\n            imgs = args[\\\"rng\\\"] * imgs\\n            imgs = imgs.clip(0, 255)\\n            imgs = imgs.round()\\n            preds.append(imgs)\\n\\n    preds = np.concatenate(preds)\\n    preds = preds.astype(np.uint8)\\n    final_preds += preds\\n\\n    del model\\n    gc.collect()\\n    torch.cuda.empty_cache()\\n\\nfinal_preds = final_preds.astype(np.uint8)\\nfinal_preds = final_preds.reshape(-1, 14400)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule = NowcastingDataModule()\n",
    "datamodule.setup(\"test\")\n",
    "\n",
    "final_preds = np.zeros((len(datamodule.test_dataset), 120, 120))\n",
    "\n",
    "for fold in range(5):\n",
    "    checkpoint = (\n",
    "        args[\"model_dir\"]\n",
    "        / f\"unet_fold{fold}_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.ckpt\"\n",
    "    )\n",
    "    print(checkpoint)\n",
    "    model = UNet.load_from_checkpoint(str(checkpoint))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(datamodule.test_dataloader()):\n",
    "            batch = batch.cuda()\n",
    "            imgs = model(batch)\n",
    "            imgs = imgs.detach().cpu().numpy()\n",
    "            imgs = imgs[:, 0, 4:124, 4:124]\n",
    "            imgs = args[\"rng\"] * imgs\n",
    "            imgs = imgs.clip(0, 255)\n",
    "            imgs = imgs.round()\n",
    "            preds.append(imgs)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    preds = preds.astype(np.uint8)\n",
    "    final_preds += preds\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "final_preds = final_preds.astype(np.uint8)\n",
    "final_preds = final_preds.reshape(-1, 14400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_formatted_code = \"test_paths = datamodule.test_dataset.paths\\ntest_filenames = [path.name for path in test_paths]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_paths = datamodule.test_dataset.paths\n",
    "test_filenames = [path.name for path in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2360942148d490c8fd59244a4e174f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"subm = pd.DataFrame({\\\"file_name\\\": test_filenames})\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = final_preds[:, i]\";\n",
       "                var nbb_formatted_code = \"subm = pd.DataFrame({\\\"file_name\\\": test_filenames})\\nfor i in tqdm(range(14400)):\\n    subm[str(i)] = final_preds[:, i]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm = pd.DataFrame({\"file_name\": test_filenames})\n",
    "for i in tqdm(range(14400)):\n",
    "    subm[str(i)] = final_preds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14390</th>\n",
       "      <th>14391</th>\n",
       "      <th>14392</th>\n",
       "      <th>14393</th>\n",
       "      <th>14394</th>\n",
       "      <th>14395</th>\n",
       "      <th>14396</th>\n",
       "      <th>14397</th>\n",
       "      <th>14398</th>\n",
       "      <th>14399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00000.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00001.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00002.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00003.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00004.npy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  14401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name  0  1  2  3  4  5  6  7  8  ...  14390  14391  14392  14393  \\\n",
       "0  test_00000.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "1  test_00001.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "2  test_00002.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "3  test_00003.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "4  test_00004.npy  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
       "\n",
       "   14394  14395  14396  14397  14398  14399  \n",
       "0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 14401 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"subm.to_csv(\\n    f\\\"unet_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.csv\\\",\\n    index=False,\\n)\\nsubm.head()\";\n",
       "                var nbb_formatted_code = \"subm.to_csv(\\n    f\\\"unet_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.csv\\\",\\n    index=False,\\n)\\nsubm.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subm.to_csv(\n",
    "    f\"unet_bs{args['batch_size']}_epoch{args['max_epochs']}_{args['optimizer']}_{args['scheduler']}.csv\",\n",
    "    index=False,\n",
    ")\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch2] *",
   "language": "python",
   "name": "conda-env-torch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
